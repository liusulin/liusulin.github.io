---
title: Home
---
<p align="center">
<img src="/media/sulin_avatar.jpeg" width="450">
</p>

<span style="font-size:2.3em;"> Hi! I'm Sulin. </span>
<a href="https://github.com/liusulin" style="border:none; position:relative; top:3px; left: 15px;" target="_blank"> <img src="https://raw.githubusercontent.com/feathericons/feather/master/icons/github.svg" width="25" height="25"></a>         <a href="https://twitter.com/su_lin_liu" style="border:none; position:relative; top:3px; left:20px;" target="_blank"> <img src="https://raw.githubusercontent.com/feathericons/feather/master/icons/twitter.svg" width="25" height="25"></a>        <a href="https://www.linkedin.com/in/sulin-liu" style="border:none; position:relative; top:3px; left:25px;" target="_blank"> <img src="https://raw.githubusercontent.com/feathericons/feather/master/icons/linkedin.svg" width="25" height="25"></a>                                                                                                          <a href="https://scholar.google.com/citations?user=s3NlgA4AAAAJ&hl=en" style="border:none; position:relative; left:24px; top:5px;" target="_blank"> <img src="/media/icons/google-scholar.svg" width="30" height="30"></a>                        <a href="/files/cv.pdf" style="border:none; position:relative; left: 24px; top:-0.9px;"><span style="font-size:1.37em;"> CV </span></a>                                                                                                        <a href="mailto:sulinliu@mit.edu" style="border:none; position:relative; left:28px;top:3px;" target="_blank"> <img src="https://raw.githubusercontent.com/feathericons/feather/master/icons/mail.svg" width="25" height="25"></a> 

I recently joined [MIT](https://www.mit.edu/) as a postdoctoral researcher working with [Rafael GÃ³mez-Bombarelli](https://gomezbombarelli.mit.edu/) on developing machine learning methods for scientific settings. I received my PhD from [Princeton University](https://www.princeton.edu/), advised by [Ryan P. Adams](https://www.cs.princeton.edu/~rpa/) and [Peter J. Ramadge](https://ee.princeton.edu/people/peter-j-ramadge/). My PhD research focuses on developing deep-learning-enabled probabilistic inference and generative modeling for knowledge discovery.

Previously, I worked with [Sinno Jialin Pan](https://personal.ntu.edu.sg/sinnopan/) on [distrbuted (federated) multi-task learning](/en/research/optimization "click for more details") at [Nanyang Technological University in Singapore](https://www.ntu.edu.sg/). Before that, I did my undergraduate in Electrical Engineering at [National University of Singapore](https://nus.edu.sg/).


## Research Areas

[**Generative marginal modeling**](/en/research/gen "click for more details")\
Approximating marginal probabilities of discrete data with neural networks, via a scalable training objective, for both maximum likelihood training and energy-based training (such as modeling Ising models, canonical ensemble of high-entropy alloys).

<p align="center">
<img src="/media/marginalization_binary_only.png" width="700">
</p>

[**Deep-learning-enabled probabilistic inference**](/en/research/deep "click for more details")\
Scaling up probabilistic inference without sacrificing effectiveness, via using deep learning to accelerate the computationally expensive procedure in probabilistic inference.

<p align="center">
<img src="/media/ahgp.png" width="700">
</p>

[**Controllable discovery**](/en/research/discovery "click for more details")\
Searching for interpretable/simple solutions or learning to control complex systems with safety guarantees.

<p align="center">
<img src="/media/probf.png" width="350"> <img src="/media/sebo.png" width="350">
</p>
<!-- 
[**Scalable optimization for ML**](/en/research/optimization "click for more details")\
Developing and analyzing scalable optimization methods for machine learning problems. -->



## Selected Publications


**Generative Marginalization Models**. [Paper]() | [Code]() | [Video](https://icml.cc/virtual/2023/29185)\
<ins>Sulin Liu</ins>, Peter J. Ramadge, Ryan P. Adams.\
*Submitted*, 2023.\
short version at *ICML Workshop on Workshop on Structured Probabilistic
Inference & Generative Modeling*. (Contributed talk, 6/125)

**Sparse Bayesian Optimization**. [Paper](https://arxiv.org/abs/2203.01900) | [Video](https://slideslive.com/38996665/sparse-bayesian-optimization?ref=search-presentations-sparse+bayesian)\
<ins>Sulin Liu</ins>\* (equal contr.), Qing Feng*, David Eriksson*, Benjamin Letham, Eytan Bakshy.\
*International Conference on Artificial Intelligence and Statistics* (AISTATS), 2023.\
short version at at *NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems*. (Contributed talk, top five selected)



<!-- **ProBF : Probabilistic Safety Certificates with Barrier Functions**. [Paper](https://arxiv.org/abs/2112.12210) | [Code](https://github.com/athindran/ProBF)\
Athindran Ramesh Kumar*, <ins>Sulin Liu</ins>\*, Jaime F. Fisac, Ryan P. Adams, Peter J. Ramadge.\
*Preprint*, 2021.\
short version at *NeurIPS Safe and Robust Control of Uncertain Systems Workshop*. -->



**Task-Agnostic Amortized Inference of Gaussian Process Hyperparameters**. [Paper](https://papers.nips.cc/paper/2020/hash/f52db9f7c0ae7017ee41f63c2a7353bc-Abstract.html) | [Code](https://github.com/PrincetonLIPS/AHGP) | [Slides](https://github.com/PrincetonLIPS/AHGP/blob/main/slides/AHGP_slides.pdf) | [Video](https://slideslive.com/38937035/taskagnostic-amortized-inference-of-gaussian-process-hyperparameters?ref=search-presentations-Task-Agnostic+Amortized+Inference+of+Gaussian+Process+Hyperparameters)\
<ins>Sulin Liu</ins>, Xingyuan Sun, Peter J. Ramadge, Ryan P. Adams.\
*Advances in Neural Information Processing Systems* (NeurIPS), 2020.\
short version at *7th ICML Workshop on Automated Machine Learning*. (Spotlight talk)


<!-- 
**Distributed Multi-Task Relationship Learning**.
[Paper](https://arxiv.org/abs/1612.04022) | [Video](https://www.youtube.com/watch?v=az3jbBl-zXI)\
<ins>Sulin Liu</ins>, Sinno Jialin Pan, Qirong Ho.\
*SIGKDD Conference on Knowledge Discovery and Data Mining* (KDD), 2017.  -->
